# Video Demo Transcript: The Automaton Auditor

**Objective**: Mastered Grade (5/5) across all video rubric dimensions.
**Target Duration**: 4:45 - 5:00 Minutes

---

## 1. Context & Strategy [0:00 - 0:45]

"Hello. I’m Natnael Alemseged, and today I’m demonstrating **The Automaton Auditor**—a multi-agent swarm designed for autonomous governance of software repositories.

The core challenge in automated auditing is LLM bias and hallucination. We solve this through **Dialectical Synthesis**. Instead of one LLM chat, we use a tiered architecture: parallel **Detectives** fan out to extract evidence from the repo, the PDF, and vision assets at once—so we don't wait on one source before starting the next. Then the **Judicial Layer**: three conflicting personas—the Prosecutor, Defense, and Tech Lead—argue over that evidence. Using three judges instead of one ensures our audit isn't just an average of opinions, but a rigorous, forensic determination."

## 2. Live Swarm Execution [0:45 - 2:00]

"Let’s run the swarm live. I’ll execute the full pipeline once, start to finish, with no cuts—so you see the real run from inputs to output.

I’m invoking the graph with my repo URL and this assessment PDF. _(Run command: python src/graph.py https://github.com/Natnael-Alemseged/Github-Evaluator audit/Project-Report.pdf)_

As it starts, notice the terminal. Here is our **Forensic Layer**—the Detective Fan-Out. You can see `[Evidence Found]` tags appearing. These aren't just strings; they are structured Pydantic objects containing file locations and confidence scores.

Now we’re in the **Judicial Layer**. Watch the terminal: the **Prosecutor** is flagging a weakness in 'Structured Output Enforcement' with a score of 4; the **Defense** argues for a 4 with different reasoning—rewarding intent; the **Tech Lead** pushes for a 5 on maintainability. Three distinct personas, visibly conflicting. This is **Fan-In / Fan-Out** orchestration—each judge is isolated to prevent collusion, so we get genuine dialectical conflict."

## 3. Layered Visibility & Conflict Resolution [2:00 - 3:15]

"How do we resolve that conflict? Our strategy is **Deterministic Conflict Resolution**. Instead of another LLM call—which would just introduce more noise—we use hardcoded Python rules in `src/nodes/justice.py`. This provides a stable, predictable 'Rule of Law' that can’t be hallucinated away.

Notice in the logs, the **Chief Justice** node is now applying a 'Prosecutor Floor' to the Git Forensic dimension. It detects the variance, cites the 'Rule of Security', and explains _why_ it settled on the final score. This is **Metacognition** in action—the system evaluating its own evaluation to ensure reliability for autonomous governance at scale."

## 4. MinMax Peer Feedback Reflection [3:15 - 4:00]

_Keep to ~45 seconds. If running over 5 min, trim to 30 sec: one peer example + one improvement._

"The system’s robustness was tested in the **MinMax Peer Feedback Loop**. When I audited a peer’s repo, my agent failed at first because their directory structure differed—so I upgraded the detectives from rigid path matching to semantic AST search. The peer report in `audit/` then caught my 'happy-path' bias: `VisionInspector` was a stub. I fixed that with a multimodal Gemini pipeline and the **Evidence Integrity Check** you saw in the terminal, which filters hallucinated file paths."

## 5. Conclusion & Final Output [4:00 - 5:00]

"The pipeline has just finished. You can see in the terminal it wrote `audit/final_audit_report.md`—this is the artifact from _this_ run. Opening it now.

It contains a full executive summary, per-criterion scores from all three judges, and concrete, file-level remediation steps.

The Automaton Auditor moves us from 'asking an AI its opinion' to 'trusting a forensic machine.' It provides the structured, adversarial, and verifiable governance required for production-scale engineering. Thank you."

---

## Technical Setup Tips for the Demo:

1. **Font Size**: Increase your terminal font size so `[Evidence Found]`, `[Judge Verdict]`, and judge names (Prosecutor / Defense / Tech Lead) are readable.
2. **Smooth Flow**: Have the `graph.py` command ready in your terminal history (arrow-up). Do not cut or pause the recording during the pipeline run.
3. **Evidence Visibility**: When you mention the "Prosecutor Floor" at [3:00], scroll the terminal to show: `[Chief Justice] PROSECUTOR FLOOR applied`.
4. **Report = This Run**: The graph prints `✅ Final Audit Report written to: audit/final_audit_report.md` when done. Point at that line—"you can see it just wrote this file"—then open the file so the grader sees the report was generated by this execution.
5. **Markdown Preview**: Use a Markdown previewer (e.g. VS Code) for `final_audit_report.md` at the end so the table and bold text look clear.
6. **Timing**: Rehearse with a stopwatch. If the live run is long, use the shortened MinMax script (Section 4) to stay under 5:00.
